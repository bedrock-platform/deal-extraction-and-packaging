# Semantic Enrichment Pipeline for Programmatic Advertising

The semantic enrichment pipeline is a sophisticated three-stage system designed to transform fragmented, sparse data from multiple advertising sources (like **Google Authorized Buyers** and **BidSwitch**) into high-value, "buyer-ready" deal packages. By leveraging Artificial Intelligence (AI) and industry-standard frameworks, the pipeline ensures that ad inventory is categorized with precision, vetted for brand safety, and bundled into logical groups that programmatic buyers can activate instantly.

---

## ğŸ¯ **What Problem Does This Solve?**

Programmatic advertising deals arrive from multiple vendors in inconsistent formats with minimal metadata. Buyers struggle to:
- **Understand what inventory they're buying** (beyond deal names)
- **Ensure brand safety** (avoiding unsuitable content)
- **Find relevant deals** (matching campaigns to appropriate inventory)
- **Scale efficiently** (manually reviewing hundreds of deals is impractical)
- **Reduce "shadow spend"** (identifying direct supply paths vs. multiple middleman fees)
- **Filter out low-quality inventory** (separating premium, high-attention inventory from "junk" scale)

This pipeline automates the entire lifecycleâ€”from raw deal extraction and packaging to curated, semantically-enriched packagesâ€”making inventory discovery and activation seamless for programmatic buyers.

---

## ğŸ’¼ **Business Value & Outcomes**

### **Transparency & Supply Path Optimization**
- **Reduced Shadow Spend:** Stage 1.5 verification (planned) will identify direct supply paths, reducing multiple "middleman" fees that inflate costs
- **SPO Scoring:** Future verification layer will check `ads.txt` files to ensure buyers are purchasing from authorized sellers, not risky third-tier resellers

### **Efficiency Gains**
- **Time-to-Market Reduction:** From **days of manual review** to **minutes of automated enrichment**
- **Scale Processing:** Handles 800+ deals automatically, reducing manual review workload by 95%+
- **Real-Time Visibility:** Incremental Google Sheets updates provide immediate insight into enrichment progress

### **Inventory Quality**
- **"North Star" Taxonomy Filtering:** Pipeline filters out "junk" scale in favor of premium, high-attention inventory
- **Quality Tier Classification:** Automatically categorizes deals as Premium, Essential, Performance, or Verified
- **Brand Safety Assurance:** GARM-compliant risk ratings protect brand reputation

### **Buyer Experience**
- **DSP-Ready Packages:** Packages match how real advertisers search in their DSPs (following industry-standard naming conventions)
- **Semantic Intelligence:** Deals grouped by meaningful relationships, not just exact taxonomy matches
- **Multi-Home Advantage:** GMM clustering allows deals to appear in multiple packages, maximizing discoverability

---

## ğŸ—ï¸ **Core Stages of the Pipeline**

The pipeline follows a structured journey from raw data to a curated marketplace of ad deals:

### **Stage 0: Unified Data Ingestion**

Different ad tech vendors speak different "languages" (schemas). This stage extracts raw data from various platforms and translates them into a single, **Unified Pre-Enrichment Schema**. This ensures that whether a deal comes from Google or BidSwitch, it is treated consistently throughout the rest of the process.

**Technical Implementation:**
- Multi-vendor architecture supporting Google Authorized Buyers, BidSwitch, and extensible to additional SSPs
- Vendor-specific transformers normalize data into a unified schema
- Handles authentication, pagination, and rate limiting automatically

### **Stage 1: Individual Deal Enrichment**

Once data is unified, it is "enriched" using advanced AI (Google Gemini 2.5 Flash) to add semantic metadata. This stage uses **AI inference** to predict the deeper meaning of a deal beyond its name. (Note: Stage 1.5 will add **live verification** to validate these inferences against real-world data.)

This stage adds critical fields such as:

* **IAB Content Taxonomy (v3.1):** Categorizing content into a three-tiered hierarchy (e.g., *Entertainment > Television > Streaming*) to help advertisers align with relevant content themes. The system validates against the complete IAB taxonomy (704 entries, 37 Tier 1 categories) with automatic correction for variations.

* **GARM Brand Safety & Suitability:** Assigning risk levels (*Floor, Low, Medium, High*) based on the **Global Alliance for Responsible Media** standards. This protects brand reputation by ensuring ads don't appear next to unsuitable content. The system also flags deals as `family_safe` for all-audience campaigns.

* **Audience Profiling:** Identifying likely audience segments (e.g., "Auto Intenders" or "Luxury Shoppers") and demographic hints based on deal characteristics and publisher intelligence.

* **Commercial Intelligence:** Classifying deals into quality tiers (*Premium, Essential, Performance, Verified*) and volume tiers (*High, Medium, Low*) to help buyers understand scale and quality.

* **Semantic Concepts:** Extracting 3-8 key semantic keywords and themes from each deal (e.g., "CTV", "Premium", "Brand-Safe", "Sports") for enhanced discoverability.

**Technical Implementation:**
- Unified LLM inference reduces processing time by ~4x (1 API call vs. 4 separate calls)
- Incremental processing with checkpointing enables resume capability for long-running jobs
- Row-by-row persistence to Google Sheets provides real-time visibility
- Publisher intelligence recognizes 30+ major brands (Paramount+, Disney+, CNN, ESPN, etc.)
- Temporal signal extraction detects seasonal patterns and flags outdated deals

### **Stage 2: Intelligent Packaging (The Grouping Engine)**

In this stage, the pipeline uses a technique called **Gaussian Mixture Model (GMM) Clustering** to group individual deals into cohesive packages.

#### **The "Multi-Home" Advantage**

Unlike simpler grouping methods, GMM is a **"soft clustering"** algorithm that recognizes strategic flexibility. A single premium deal (e.g., *Monday Night Football*) can logically belong in multiple packages simultaneously:
- **"Premium Sports" package** (taxonomy-based grouping)
- **"Premium CTV" package** (format-based grouping)
- **"High-Attention" package** (audience-based grouping)

This "multi-home" approach maximizes deal exposure to different buyer needs, ensuring that high-value inventory is discoverable through multiple search paths in DSPs.

#### **Constraint-Based Logic**

While clustering is automated, it is **bounded by the "North Star" Taxonomy**â€”a curated list of package types that major demand-side platforms (DSPs) and advertisers expect to see (e.g., *High-Efficiency Performance, Live Sports & Enthusiasts, or Seasonal Shopping*). This ensures every package generated has a clear, recognizable market purpose and matches how real advertisers search in their DSPs.

#### **LLM-Driven Naming & Auditing**

Each cluster is analyzed by AI in a two-step process:

**Step 1: Cluster Auditing** (Quality Assurance)
- **Semantic Density Check**: Evaluates whether all deals share coherent "communicative logic"
- **Safety & Compliance Safeguards**: Identifies and separates deals with conflicting GARM risk ratings or regulatory requirements
- **Commercial Quality Alignment**: Flags quality tier mismatches (e.g., Premium vs. RON) and price range conflicts
- **Outlier Detection**: Identifies mathematical outliers that don't belong in the cluster
- **Boundary Refinement**: Re-homes "edge deals" that sit between clusters

**Step 2: Package Proposal**
- Proposes buyer-friendly package names following industry-standard naming conventions (Quality Prefix + Vertical/Audience + Format + "Package")
- Documents excluded deals and reasoning for transparency
- Considers:
  - **Taxonomy alignment** (exact + complementary categories)
  - **Audience synergy** (segments that work well together)
  - **Safety consistency** (matching risk levels)
  - **Commercial synergies** (quality tiers, price ranges)
  - **Use case alignment** (campaign types, verticals)

This auditing step ensures packages are **commercially viable** and **safe for buyers**, not just mathematically similar. It's the difference between a "black box" and an **auditable marketplace** that buyers can trust.

**Technical Implementation:**
- Semantic embeddings created using `sentence-transformers` (all-MiniLM-L6-v2)
- Adaptive clustering: ~25 deals per cluster (optimal for LLM processing)
- GMM supports deal overlap strategy (deals can appear in multiple packages)
- **LLM auditing integrated** into package proposal step (adds ~1-2 minutes to Stage 2, not a separate hours-long job)
- Estimated output: 70-100 packages from 800+ deals

### **Stage 3: Health Scoring & Recommendations**

The final stage evaluates the quality of the newly created packages. It calculates a **Health Score** based on data completeness and volume. Finally, an LLM generates human-readable recommendations, explaining the value proposition of the package and suggesting specific use cases for buyers.

**Technical Implementation:**
- Aggregated metadata: taxonomy consensus, safety aggregation (worst-case), price ranges, volume sums
- Health scoring algorithm evaluates package quality
- LLM generates use case recommendations and buyer guidance

### **Stage 1.5: Real-Time Verification Layer** (Planned)

Moving beyond **static inference** (predicting based on deal metadata) to **dynamic verification** (validating against the live web). This upcoming enhancement adds real-time intelligence by verifying supply paths, auditing site quality, and ensuring compliance.

#### **Supply Path Optimization (SPO)**
- **ads.txt Verification:** Cross-references publisher domains against public `ads.txt` files to verify deals are sourced from direct, authorized sellers
- **Shadow Spend Reduction:** Identifies when buyers are paying multiple "middleman" fees, enabling direct path optimization
- **SPO Scoring:** Classifies deals as Direct (high), Authorized Reseller (medium), or Unknown (low) based on supply path validation

#### **Site Quality Auditing**
- **MFA Detection:** Uses **Gemini Vision** to audit site quality and detect Made-For-Advertising (MFA) sitesâ€”a top-of-mind concern for advertisers in 2026
- **Visual Content Analysis:** Real-time publisher site crawling to verify content quality and brand safety
- **E-E-A-T Scoring:** Authority scoring based on search visibility and content quality signals

#### **Compliance Verification**
- **Privacy Regulation Compliance:** Automated verification of GDPR/TCF 2.2 compliance and Consent Management Platform (CMP) versions
- **Regulatory Alignment:** Flags non-compliant publishers for exclusion, ensuring deals meet latest privacy regulations

**Status:** Stage 1.5 is planned for Phase 4, after Stage 2 (Package Creation) is operational. This allows focus on completing the essential pipeline (Stage 0â†’1â†’2â†’3) before adding verification enhancements.

---

## ğŸ“Š **Key Enrichment Fields Explained**

To make deals easy to understand for buyers, the pipeline focuses on these primary semantic fields:

| Field Type | Description | Buyer Value |
| --- | --- | --- |
| **Taxonomy** | IAB Content Tiers (1, 2, and 3). Validated against IAB v3.1 taxonomy (704 entries). | Ensures the ad context matches the product vertical. |
| **GARM Safety** | Risk rating (Floor to High) and family-safe flag. | Provides a common vocabulary to define brand suitability needs. |
| **Audience** | Inferred intender segments and demographics. | Increases precision and reduces "wasted" ad spend. |
| **Commercial** | Quality tiers (Premium, Essential, Performance, Verified) and volume metrics. | Helps buyers understand the scale and quality of the inventory. |
| **Concepts** | Semantic keywords and themes (3-8 per deal). | Enhances discoverability and searchability. |

---

## ğŸŒŸ **The "North Star" Taxonomy for Packaging**

To ensure the pipeline generates commercially viable results, clustering is refined using categories that dominate the programmatic market:

* **Performance & Outcomes:** Deals optimized for metrics like high viewability or click-through rates.
* **Vertical-Specific:** Packages tailored for industries like Automotive, Financial Services, or CPG/Retail.
* **Environment & Format:** Specialized bundles for **CTV (Connected TV)**, mobile apps, or high-impact video.
* **Supply Path Optimization (SPO):** Packages that emphasize direct, transparent paths to premium publishers, reducing middleman fees.

By automating this complex lifecycle, the pipeline ensures that inventory is not just "sold," but **curated** to meet the specific strategic goals of modern advertisers.

---

## ğŸ”— **Unified Logic: Bridging the Vocabulary Gap**

Different ad tech vendors use different "vocabularies" (schemas, field names, data structures). The pipeline's **Unified Pre-Enrichment Schema** solves this by:

* **Normalizing Vendor Differences:** Google Authorized Buyers uses `impressions` while BidSwitch uses `bid_requests`â€”the pipeline translates both into a unified `inventory_scale` metric
* **Consistent Field Mapping:** Vendor-specific fields (e.g., Google's `entityName` vs. BidSwitch's `deal_name`) are mapped to a single `deal_name` field
* **Schema Validation:** Pydantic v2 ensures all transformed data meets the unified schema before enrichment begins

This unified approach ensures that downstream stages (enrichment, packaging) work consistently regardless of the source vendor, eliminating the need for vendor-specific logic in later stages.

---

## ğŸ›¡ï¸ **Compliance & Standards**

The pipeline ensures compliance with industry standards and regulations:

### **GARM (Global Alliance for Responsible Media)**
- **Risk Rating Assignment:** All deals receive GARM-compliant risk ratings (Floor, Low, Medium, High)
- **Family-Safe Flagging:** Deals are flagged as `family_safe` for all-audience campaigns
- **Brand Safety Aggregation:** Package-level safety uses worst-case aggregation (most restrictive rating)

### **IAB Content Taxonomy v3.1**
- **Complete Taxonomy Coverage:** Validates against all 704 entries (37 Tier 1, 323 Tier 2, 275 Tier 3 categories)
- **Automatic Correction:** Fuzzy matching corrects LLM variations (e.g., "Automotive" vs. "Automotive & Vehicles")
- **Backward Compatibility:** Supports v2.2 category names with automatic mapping to v3.1

### **Privacy Regulations** (Planned in Stage 1.5)
- **GDPR/TCF 2.2 Compliance:** Future verification layer will check Consent Management Platform (CMP) versions
- **Privacy-First Design:** Pipeline designed to work with first-party contextual signals, reducing reliance on third-party cookies

---

## ğŸ¯ **Buyer Context: Matching DSP Search Patterns**

The pipeline creates packages that match how real advertisers search in their DSPs:

* **Industry-Standard Naming:** Package names follow the format buyers expect: `[Quality] [Vertical/Audience] [Format] Package`
* **DSP-Ready Categories:** Packages align with standard DSP filters (Performance, Premium CTV, Auto Intenders, etc.)
* **Searchable Concepts:** Each deal includes 3-8 semantic keywords that enhance DSP searchability
* **Multi-Dimensional Grouping:** Deals grouped by taxonomy, format, safety, quality tier, and use caseâ€”matching how buyers filter inventory

This buyer-centric approach ensures that packages are not just technically correct, but **commercially viable** and **instantly discoverable** in programmatic buying platforms.

---

## ğŸš€ **Future-Proofing & Roadmap**

The pipeline architecture is designed to handle upcoming industry shifts:

### **Privacy-First Evolution**
- **Contextual Signals:** Pipeline prioritizes first-party contextual signals over third-party cookies
- **Semantic Targeting:** Enrichment focuses on content taxonomy and audience inference, reducing cookie dependency

### **Sustainability & Green Media** (Planned)
- **Carbon Footprint Metrics:** Future plans to incorporate "carbon footprint" or "ad-clutter" metrics into commercial profiles
- **Efficiency Scoring:** Packages may include environmental impact scores to support green media initiatives

### **Enhanced Verification** (Stage 1.5 - Phase 4)
- **Real-Time Publisher Audits:** Live content analysis and risk assessment
- **Market Intelligence Fusion:** Integration with external ad intelligence platforms for competitor spend tracking
- **Performance Data Enrichment:** Historical performance metrics (CPA, conversion rates) to guide package recommendations

### **Extensibility**
- **Multi-Vendor Architecture:** Easy addition of new SSP vendors (IndexExchange, OpenX, etc.)
- **Modular Design:** Each stage can be enhanced independently without disrupting the pipeline
- **API-First Approach:** Pipeline components expose APIs for integration with external systems

---

## ğŸš€ **Quick Start**

### Prerequisites

- Python 3.9+
- Google Gemini API key (for enrichment)
- Google Sheets API credentials (optional, for export)
- Vendor-specific credentials (Google Authorized Buyers, BidSwitch)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd deal-extraction-and-packaging

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `.env` file with your credentials:

```bash
# Required for enrichment
GEMINI_API_KEY=your_gemini_api_key

# Optional: Google Sheets export
GOOGLE_SHEETS_ID=your_sheets_id

# Google Authorized Buyers (see docs/authentication-architecture.md)
AUTHORIZED_BUYERS_ACCOUNT_ID=your_account_id
AUTHORIZED_BUYERS_SAPISIDHASH=your_sapisidhash_token
AUTHORIZED_BUYERS_COOKIES=your_cookies

# BidSwitch
BIDSWITCH_USERNAME=your_username
BIDSWITCH_PASSWORD=your_password
DSP_SEAT_ID=your_seat_id
```

### Basic Usage

#### Extract and Enrich Deals

```bash
# Extract from all vendors and enrich
python -m src.deal_extractor --all --enrich

# Extract from specific vendor
python -m src.deal_extractor --vendor google_ads --enrich

# Enrich existing unified TSV file
python -m src.deal_extractor --enrich-from-tsv output/deals_unified_2026-01-21T0440.tsv
```

#### Extract Only (No Enrichment)

```bash
# Extract from all vendors
python -m src.deal_extractor --all

# Extract with filters
python -m src.deal_extractor --vendor bidswitch --inventory-format video --countries US
```

---

## ğŸ“ **Output Files**

All files are saved to the `output/` directory with ISO 8601 timestamps:

### Raw Extraction
- `deals_*.json` - Multi-vendor JSON (all vendors)
- `deals_unified_*.tsv` - Unified TSV (all vendors combined)
- `deals_*_*.tsv` - Vendor-specific TSV files

### Enriched Data
- `deals_enriched_*.jsonl` - Enriched deals (JSON Lines format, one per line)
- `deals_enriched_*.tsv` - Enriched deals (flattened TSV with all enrichment fields)
- `checkpoint_enrichment_*.json` - Checkpoint file for resume capability

### Google Sheets Export
- **Unified Worksheet:** Pre-enrichment data uploaded first, then enriched incrementally
- **Vendor-Specific Worksheets:** Separate sheets for each vendor

---

## âš™ï¸ **Pipeline Performance**

### Enrichment Speed
- **~12 seconds per deal** (unified LLM inference)
- **~2-3 hours for 800 deals** (full enrichment run)
- **Incremental processing** with checkpointing enables resume from interruption

### Package Creation
- **~32 clusters** from 800 deals (adaptive clustering)
- **~70-100 packages** estimated output (with deal overlap)
- **GMM clustering** supports soft assignments for maximum package diversity

---

## ğŸ“š **Documentation**

- **[Situation Report](plans/semantic-enrichment-pipeline/sit_rep.md)** - Comprehensive project status and architecture overview
- **[Unified Schema Definitions](docs/unified-schema-field-definitions.md)** - Complete field reference for enriched deals
- **[Authentication Architecture](docs/authentication-architecture.md)** - Technical guide for vendor authentication
- **[Implementation Plan](plans/semantic-enrichment-pipeline/PLAN.md)** - Detailed development roadmap

---

## ğŸ›ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 0:       â”‚  Extract deals from multiple vendors
â”‚  Data Ingestion â”‚  (Google Authorized Buyers, BidSwitch)
â”‚  Unified Schema â”‚  Normalize vendor differences
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1:        â”‚  Enrich individual deals with AI
â”‚  Deal Enrichment â”‚  (Taxonomy, Safety, Audience, Commercial)
â”‚  AI Inference    â”‚  Google Gemini 2.5 Flash
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º (Planned) â”€â”€â”
         â”‚                â”‚
         â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2:        â”‚  â”‚  Stage 1.5:     â”‚  (Planned - Phase 4)
â”‚  Package Creationâ”‚  â”‚  Verification    â”‚  ads.txt, SPO, MFA Detection
â”‚  GMM Clustering  â”‚  â”‚  Real-Time Truth â”‚  Gemini Vision, Compliance
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3:        â”‚  Score and recommend packages
â”‚  Package         â”‚  (Health Scoring + Use Cases)
â”‚  Enrichment      â”‚  LLM-generated recommendations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ **Technical Details**

### Supported Vendors
- âœ… **Google Authorized Buyers** - Internal API with SAPISIDHASH authentication
- âœ… **BidSwitch** - Deals Discovery API with OAuth2 authentication
- ğŸ”„ **Extensible architecture** for adding additional SSPs

### Key Technologies
- **AI/LLM:** Google Gemini 2.5 Flash for semantic inference
- **Clustering:** scikit-learn (GMM, K-means) for package grouping
- **Embeddings:** sentence-transformers (all-MiniLM-L6-v2)
- **Data Validation:** Pydantic v2 for schema enforcement
- **Export:** Google Sheets API (gspread) for real-time updates

### Project Structure

```
deal-extraction-and-packaging/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/              # Shared utilities and orchestrators
â”‚   â”œâ”€â”€ google_ads/          # Google Authorized Buyers integration
â”‚   â”œâ”€â”€ bidswitch/           # BidSwitch integration
â”‚   â”œâ”€â”€ enrichment/          # Stage 1: Deal enrichment
â”‚   â”‚   â”œâ”€â”€ inference.py    # LLM inference logic
â”‚   â”‚   â”œâ”€â”€ checkpoint.py   # Resume capability
â”‚   â”‚   â””â”€â”€ incremental_exporter.py  # Row-by-row persistence
â”‚   â”œâ”€â”€ package_creation/   # Stage 2: Package clustering
â”‚   â””â”€â”€ package_enrichment/ # Stage 3: Package scoring
â”œâ”€â”€ config/
â”‚   â””â”€â”€ enrichment/          # LLM prompt templates
â”œâ”€â”€ data/
â”‚   â””â”€â”€ iab_taxonomy/        # IAB v3.1 taxonomy reference
â”œâ”€â”€ docs/                    # Documentation
â””â”€â”€ output/                  # Generated files
```

---

## ğŸ“ **For Non-Technical Stakeholders**

### What This Means for Your Business

**Before the Pipeline:**
- **Days of manual review** required for every campaign
- Inconsistent categorization across vendors (Google vs. BidSwitch)
- Brand safety concerns (ads appearing next to unsuitable content)
- Time-consuming inventory discovery (hours per campaign)
- "Shadow spend" from multiple supply path fees
- Difficulty identifying premium vs. low-quality inventory

**After the Pipeline:**
- **Minutes of automated enrichment** (from days to minutes)
- **Automated categorization** using industry-standard taxonomies (IAB v3.1)
- **Brand safety assurance** with GARM-compliant risk ratings
- **Intelligent packaging** that groups related deals automatically
- **Buyer-ready inventory** that can be activated immediately in DSPs
- **Supply path transparency** (planned) to reduce shadow spend
- **Quality filtering** that separates premium inventory from "junk" scale

### ROI & Business Impact

#### **Efficiency Gains**
- **Time-to-Market Reduction:** From **days of manual review** to **minutes of automated enrichment** (~95% reduction)
- **Scale Processing:** Handles 800+ deals automatically (vs. manual review of ~10-20 deals per hour)
- **Real-Time Visibility:** Incremental Google Sheets updates provide immediate insight into enrichment progress

#### **Cost Optimization**
- **Shadow Spend Reduction:** Stage 1.5 verification (planned) will identify direct supply paths, reducing multiple "middleman" fees
- **Premium Inventory Focus:** "North Star" taxonomy filters out low-quality inventory, focusing spend on high-value deals
- **Reduced Manual Labor:** Automation eliminates need for dedicated deal review staff

#### **Quality & Compliance**
- **Consistent Categorization:** Validated against IAB v3.1 taxonomy (704 entries) with automatic correction
- **Brand Safety Protection:** GARM-aligned risk ratings reduce brand reputation risk
- **Regulatory Compliance:** Future verification layer ensures GDPR/TCF 2.2 compliance

#### **Buyer Experience**
- **DSP-Ready Packages:** Packages match how advertisers search in their DSPs, reducing activation time
- **Semantic Intelligence:** Deals grouped by meaningful relationships, not just exact matches
- **Multi-Dimensional Discovery:** Deals discoverable through multiple search paths (taxonomy, format, safety, quality)

---

## ğŸ¤ **Contributing**

This project uses an extensible architecture. To add new vendors or features:

1. Implement vendor-specific client and transformer (see `src/google_ads/` for reference)
2. Register in the orchestrator (`src/common/orchestrator.py`)
3. Update CLI support (`src/deal_extractor.py`)

---

## ğŸ“ **License**

MIT
